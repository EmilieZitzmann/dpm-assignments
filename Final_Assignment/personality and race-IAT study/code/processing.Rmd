---
title: "Examining the relationship between the big-5 personality facets and implicit racial attitudes"
subtitle: "Data processing"
author: "Template: Ian Hussey; content: Emilie"
date: "`2023-12-28`"
output:
  html_document:
    code_folding: hide
    highlight: haddock
    theme: flatly
    toc: yes
    toc_float: yes
---

```{r, include=FALSE}
#By this we set the knitr options (warnings and messages generated through R will not be shown in the final document)

knitr::opts_chunk$set(message = FALSE,
                      warning = FALSE)


```

# Dependencies

```{r}

library(tidyverse)
library(janitor) 
library(stringr)
library(openxlsx)
library(kableExtra)

```

# Get data

```{r}

# Demographics
data_raw_demographics <- read_csv("../data/raw/data_raw_demographics.csv") |>
  janitor::clean_names()

# Self report measure big five inventory 
data_raw_bfi <- read_csv("../data/raw/data_raw_bfi.csv") |>
  janitor::clean_names()

# Implicit association test
data_raw_iat <- read_csv("../data/raw/data_raw_iat.csv") |>
  janitor::clean_names()

```

# Demographics

Study participants had the option to provide their age and gender, although this was optional, meaning that missing data is not considered an exclusion criterion in this context. 


## Extraction of Age and Gender

Age and Gender should be extracted from the data frame. As these are both within "variable" we have to create two new variables by using pivot_wider. 

Beforehand we have to check if there is duplicated or NA data within the unique_Id in the raw dataset. By creating the dataframe "check_Id" it becomes apparent that we have duplicated data and data with NA.

The missing and duplicated values are extracted in a second step. Values other than the specified ones are set to "other/missing/error" in order to exclude them only at a later point, if needed. 

```{r}

#Dataframe to check whether we have NA or duplicated unique_Id
check_Id <- data_raw_demographics |>
  select(unique_id, variable, response) |>
  mutate(exclude_Id= ifelse (is.na(unique_id) | duplicated(unique_id) |duplicated(unique_id, fromLast = T), 
                             "missing", 
                             "inlcude")) |>
  group_by(unique_id) 

#Creating a new dataset where we exclude the NA and the duplicated rows. Be careful not to just exclude the "missing" ones from above as this would make both unique_id values disappear. 

dat_age_gender <- data_raw_demographics |>
  select(unique_id, variable, response) |>
 filter(!duplicated(unique_id) & !is.na(unique_id)) |> #filter out duplicated and NA
  pivot_wider(names_from = variable,
              values_from = response) |> 
  rename(gender = sex) |>
  mutate(gender = case_when( gender %in% c("f", "m") ~ gender, #returns current value for gender if TRUE
                             is.na(gender) ~ "other/missing/error", #if gender equals NA
                             TRUE ~ "other/missing/error"), #if none of the set conditions is true 
         age = case_when(str_detect(age, "^[0-9]+$") ~ age, #setting the wanted value for age = number
                         is.na(age) ~ "other/missing/error",#if age equals NA
                         TRUE ~ "other/missing/error")) 

```


#BFI 

As part of the study, each respondent was asked to complete between two and three subscales of the Big 5 personality inventory.

First it is checked, whether the bfi_dataset has any duplicated rows. This is not the case which is why we will continue working with the raw_bfi dataset. 

```{r}

check_bfi <-  data_raw_bfi |> 
  distinct() 


```



## Reverse Score negatively worded items

Specific items were worded negatively. These items need to be reversed in order to be suitable for analysis. This applies to the items: 

•	the extroversion scale items: bfi_e2, bfi_e5, bfi_e7
•	conscientiousness items: bfi_c2, bfi_c4, bfi_c5, bfi_c9
•	neuroticism items: bfi_n2, bfi_n5, bfi_n7
•	agreeableness items: bfi_a1, bfi_a3, bfi_a6, bfi_a8
•	openness items: bfi_o7, bfi_o9 
 
Each value can reach a maximum of 6 and a minimum of 1. In order to return the Items we must remember that the reverted scale is behaving inversely to the positive one so 1 = 6, 2 =5, 3=4, 4=3, 2= 5, 6=1. 
The easiest way to revert a Scale is  to add 1 to the maximum value in order to subtract the original value from it. This way we get the reversed score value. 

To modify the data the mutate() function is used, to apply the function on multiple columns e.g. the produced vector we can use across(). 

```{r}

vector_reversed_items <- c("bfi_e2","bfi_e5","bfi_e7","bfi_c2","bfi_c4","bfi_c5","bfi_c9","bfi_n2","bfi_n5", "bfi_n7","bfi_a1", "bfi_a3","bfi_a6","bfi_a8","bfi_o7","bfi_o9")


dat_reversed_items <- data_raw_bfi |>
  mutate(across(all_of(vector_reversed_items), ~7 - .)) #"." represents column values that are subtracted                                                            from 7 by ~7. This produces the reverted items. 
 
```


###Sanity Check 

1. To check whether the reversals are likely to be correct a correlation matrix for each variable is           created. If the correlation is negative or rather low it could indicate that the reversing was not          carried out properly. As the Big Five tend to be normally distributed the Pearson correlation is used to
   calculate the matrix. The "use" within the correlation function is set to complete.obs, which means that    variables who are missing data are not included. This is important considering that the participants only    filled out two or three of the subscales which is producing some NA for each row, hindering to calculate    the correlation correctly. 

   In order to make sure that the correlation stayed the same the correlation matrix is calculated with the    original dataset and compared with the reversed one. 

```{r}

#Extroversion
Matrix_extroversion_reversed <- dat_reversed_items |>
  select(contains("bfi_e")) |>
  cor(method = "pearson", use = "complete.obs")

Matrix_extroversion_original <- data_raw_bfi |>
   select(contains("bfi_e")) |>
  cor(method = "pearson", use = "complete.obs")


#Conscientiousness 
Matrix_conscient_reversed <- dat_reversed_items |>
  select(contains("bfi_c")) |>
  cor(method = "pearson", use = "complete.obs")

Matrix_conscient_original <- data_raw_bfi |>
   select(contains("bfi_c")) |>
  cor(method = "pearson", use = "complete.obs")


#Neuroticism
Matrix_neuroticism_reversed <- dat_reversed_items |>
  select(contains("bfi_n")) |>
  cor(method = "pearson", use = "complete.obs")

Matrix_neuroticism_original <- data_raw_bfi |>
   select(contains("bfi_n")) |>
  cor(method = "pearson", use = "complete.obs")


#Agreeableness
Matrix_agreeable_reversed <- dat_reversed_items |>
  select(contains("bfi_a")) |>
  cor(method = "pearson", use = "complete.obs")

Matrix_agreeable_original <- data_raw_bfi |>
   select(contains("bfi_a")) |>
  cor(method = "pearson", use = "complete.obs")


#Openness
Matrix_openness_reversed <- dat_reversed_items |>
  select(contains("bfi_o")) |>
  cor(method = "pearson", use = "complete.obs")

Matrix_openness_original <- data_raw_bfi |>
   select(contains("bfi_o")) |>
  cor(method = "pearson", use = "complete.obs")


```



2. A second sanity check is that the logical minimum (1) and maximum (6) are not violated. In order to check    that an exclusion variable is created that sets participants with impossible data to "exclude". Again       specific information is selected with c_across()

```{r}

#Defining the vector for maximum and minimum 

logical_min <- 1 
logical_max <- 6

#creating the dataset 
data_logical_number <- dat_reversed_items |>
  rowwise() |>
  mutate(logical_number = ifelse(any(!is.na(c_across(contains("bfi"))) & #selected values are not NA
                                     (c_across(contains("bfi")) < logical_min | 
                                      c_across(contains("bfi")) > logical_max)),
                                 "exclude",
                                 "include"))
 
#Check if we have some that violate the minimum and maximum and who it is 
data_logical_number |>
  filter(logical_number == "exclude") |>
  select(unique_id) |>
  kable() |>
  kable_classic(full_width = FALSE)

#After manually checking we can see that they all have "7" in one answer which is why they are excluded


```


3. A third sanity check for the Bfi data is provided through checking wheter all participants have complete data for the surveys they completed. First there is a new variable created for each survey, where "include" is assigned if all values in the specified row of the survey are present and non-missing. The "excluded" ones are then filtered out. After putting all of the information together in a new dataframe, subjects that completed fewer than 2 questionnaires are filtered out. This way it is ensured that only absolutely necessary exclusions are carried out, as it might be the case that someone with missing information has 2 questionnaires still completed. In a final step it is joined with the reversed dataframe and the newly added rows are removed what leaves us with a cleaned dataframe. 


```{r}

#Extroversion
 data_extroversion_exclusion <- dat_reversed_items |> 
   rowwise() |> 
   mutate(completed_q_e = ifelse(all(!is.na(c_across(contains("bfi_e")))), "include", "exclude")) |>
   filter(completed_q_e != "exclude") 
 
#Conscientiousness
data_conscient_exclusion <- dat_reversed_items |> 
  rowwise() |> 
  mutate(completed_q_c = ifelse(all(!is.na(c_across(contains("bfi_c")))), "include", "exclude")) |> 
  filter(completed_q_c != "exclude")
 

#Neuroticism
data_neuroticism_exclusion <- dat_reversed_items |> 
  rowwise() |> 
  mutate(completed_q_n = ifelse(all(!is.na(c_across(contains("bfi_n")))), "include", "exclude")) |>
  filter(completed_q_n != "exclude")

#Agreeableness
data_agreeable_exclusion <- dat_reversed_items |> 
  rowwise() |> 
  mutate(completed_q_a = ifelse(all(!is.na(c_across(contains("bfi_a")))), "include", "exclude")) |>
  filter(completed_q_a != "exclude")

#Openness
data_openness_exclusion <- dat_reversed_items |> 
  rowwise() |> 
  mutate(completed_q_o = ifelse(all(!is.na(c_across(contains("bfi_o")))), "include", "exclude")) |>
  filter(completed_q_o != "exclude")



#combining all of the information above within one dataframe and checking whether each person has at least completed 2 Bfi Scales 

data_combined_exclusion <- dat_reversed_items |>
  select(unique_id) |>
  left_join(data_extroversion_exclusion |>
            select(unique_id, completed_q_e), by = "unique_id") |>
  left_join(data_conscient_exclusion |>
            select(unique_id, completed_q_c), by = "unique_id") |>
  left_join(data_neuroticism_exclusion |>
            select(unique_id, completed_q_n), by = "unique_id") |>
  left_join(data_agreeable_exclusion |>
            select(unique_id, completed_q_a), by = "unique_id") |>
  left_join(data_openness_exclusion |>
            select(unique_id, completed_q_o), by = "unique_id") |>
  rowwise() |>
  mutate(completed_questionnaires = sum(!is.na(c(completed_q_e, 
                                                 completed_q_c, 
                                                 completed_q_n,
                                                 completed_q_a,
                                                 completed_q_o)))) |>
  filter(completed_questionnaires >= 2)  


#Making a final dataframe with only the ones that should be included

data_completed_exclusion <- dat_reversed_items |>
  left_join(data_combined_exclusion, by = "unique_id") |>
  rowwise() |>
  mutate(completed_questionnaires = sum(!is.na(c(completed_q_e, 
                                                 completed_q_c, 
                                                 completed_q_n,
                                                 completed_q_a,
                                                 completed_q_o)))) |>
  filter(completed_questionnaires >= 2) |>
  select(-contains("completed")) # removing the completed labels as they are not adding information to the                                     new dataframe

```


##Mean score BFI

Mean-score the subscales of the BFI scale. Each participant only got either 2 or 3 subscales.
Check that the mean scores do not violate the min and max possible score (i.e., first determine this min and max score), and revise your scoring code if it does.


We take dat reversed Items but probably after the interpretation we have to be more careful with it 

```{r}

data_mean_bfi <- dat_reversed_items |> 
  rowwise() |>
  mutate(mean_extroversion = mean(c_across(contains("bfi_e")), na.rm =T),
         mean_conscient = mean(c_across(contains("bfi_c")), na.rm = T),
         mean_neuroticism = mean(c_across(contains("bfi_n")), na.rm = T),
         mean_agreeable = mean(c_across(contains("bfi_a")), na.rm =T),
         mean_openness = mean(c_across(contains("bfi_o")), na.rm =T))


#Check for violation of the scores, do not take the same vector name as above because if there is some change done in either of them the calculation will be confused.

min_possible_score <- 1  
max_possible_score <- 6  

#Still issues with this 

data_mean_violation_bfi <- data_mean_bfi |>
  rowwise() |>
  mutate(score_violation = ifelse(any(c_across(contains("bfi")) 
                                      < min_possible_score | c_across(contains("bfi")) 
                                      >max_possible_score, na.rm = T),
                                  "yes", 
                                  "no")) |>
  ungroup() |>
  select(unique_id, mean_extroversion, mean_conscient, mean_neuroticism, mean_agreeable, mean_openness,
         score_violation)
 





```



```{r}

data_amp_performance_criteria <- data_amp_raw |> 
  filter(blockcode != "practice", 
         trialcode != "instructions") |> 
  mutate(latency_prob = if_else(latency < 100, TRUE, FALSE)) |> 
  group_by(subject) |> 
  summarize(proportion_fast_trials_amp = mean(latency_prob)) |>
  mutate(exclude_amp_performance = ifelse(proportion_fast_trials_amp > 0.10, "exclude", "include"))

# determine modal number of trials
data_amp_completeness <- data_amp_raw |>
  filter(blockcode != "practice",
         trialcode != "instructions") |>
  group_by(subject) |>
  count() |>
  ungroup() |>
  mutate(exclude_amp_completeness = ifelse(n == 72, "include", "exclude")) |>
  select(-n)

# data_amp_completeness |>
#   count(n)

```

- One participant with 8 trials appears to be a partial completion (check raw data?)
- One participant with 144 trials appears to be a repeat participant. I've chosen to exclude them entirely, but you could also have a more elaborate strategy where you retain only their first completion.

# Self-reports

```{r}

# trial level data
data_selfreport_trial_level <- data_selfreport_raw |>
  select(subject, trialcode, response) |>
  filter(trialcode %in% c("like", "prefer", "positive")) |>
  rename(item = trialcode) |>
  filter(response != "Ctrl+'B'") |>
  mutate(response = as.numeric(response))

# mean scored
data_selfreport_mean_score <- data_selfreport_trial_level |>
  group_by(subject) |>
  summarize(mean_evaluation = mean(response, na.rm = TRUE))

# combined
data_selfreport_scored <- 
  full_join(data_selfreport_trial_level |>
              pivot_wider(names_from = "item",
                          values_from = "response"),
            data_selfreport_mean_score,
            by = "subject")

```

# Affect Misattribution Procedure

TODO extract evaluations on the AMP test blocks and convert to an overall bias score

```{r}

data_amp_score_congruence <- data_amp_raw |> 
  select(subject, evaluative_response = correct, trialcode, blockcode) |> 
  filter(blockcode != "practice", 
         trialcode != "instructions") |> 
  mutate(trialcode = case_when(trialcode == "prime_positive" ~ 1, 
                               trialcode == "prime_negative" ~ 0,
                               TRUE ~ NA),
         prime_congruence = ifelse(trialcode == evaluative_response, 1, 0)) 

# sanity check 1: if you consider all the combiantions of factor levels of trialcode, evaluative_response, and prime congruence, there should be only 4:
data_amp_score_congruence |>
  count(trialcode, evaluative_response, prime_congruence)

data_amp_score_congruence |>
  count(trialcode, evaluative_response, prime_congruence) |>
  nrow() == 4

# calculate AMP score 
data_amp_score <- data_amp_score_congruence |> 
  group_by(subject) |> 
  summarize(AMP_score = mean(prime_congruence, na.rm = TRUE)) |> 
  select(subject, AMP_score)

# sanity check 2: check if AMP_score is numeric 
is.numeric(data_amp_score$AMP_score)

# sanity check 3: check if AMP_score is bounded [0,1]
data_amp_score |> 
  mutate(bounded_correctly = between(AMP_score, left = 0, right = 1)) |>
  filter(bounded_correctly != TRUE) |>
  nrow() == 0

```

# Combine

```{r}

# combine all dfs created in the previous chunks
data_processed_temp <- dat_age_gender |>
  full_join(data_selfreport_scored, by = "subject") |> 
  full_join(data_amp_score, by = "subject") |> 
  full_join(data_amp_performance_criteria, by = "subject") |>
  full_join(data_amp_completeness, by = "subject")

# flag all subjects with more than one row in the wide-format data. these should be excluded in the analysis.
# a more elaborate approach would be to track down the individual dupicate cases and determine which of the mulitiple cases should be retained. 
data_processed_duplicates <- data_processed_temp |>
  count(subject) |>
  mutate(exclude_duplicate_data = if_else(n > 1, "exclude", "include")) |>
  select(-n)

# join in the duplicates df
data_processed_before_exclusions <- data_processed_temp |>
  full_join(data_processed_duplicates, by = "subject")

```

# Define master exclusions

```{r}

# create a master exclude_participant variable
data_processed <- data_processed_before_exclusions |>
  mutate(exclude_participant = case_when(tolower(age) == "test" ~ "exclude",
                                         tolower(gender) == "test" ~ "exclude",
                                         is.na(mean_evaluation) ~ "exclude",
                                         # in this case we will exclude participants with missing demographics data or outcomes measures data. 
                                         # Note that "list-wise exclusions" like this aren't always justified, as missingness often isn't at random. 
                                         # How to treat missing data is a  whole area of work in itself, which we wont cover here.
                                         is.na(age) ~ "exclude", 
                                         is.na(gender) ~ "exclude",
                                         exclude_amp_performance == "exclude" ~ "exclude",
                                         exclude_duplicate_data == "exclude" ~ "exclude",
                                         exclude_amp_completeness == "exclude" ~ "exclude", 
                                         TRUE ~ "include"))

```

# Write to disk

```{r}

# in case this dir doesn't exist, create it
dir.create("../data/processed/")

# save data to disk in that dir
write_csv(data_processed, "../data/processed/data_processed.csv")

```

# Create codebook template for the processed data

If it has not already been created, this code write the codebook template to disk. 

\TODO The template should then be filled in manually with descriptions of each variable so that someone else could understand what these variables represent. 

Be sure to ALWAYS do it, since people forget the labels, the maximum and minimum values etc. We should also specify what they should be (numeric etc.)


I filled out some parts of the codebook but I am not sure whether it is visible on Github:)

```{r}

if(!file.exists("../data/processed/data_processed_codebook.xlsx")){
  # convert the column names to a df
  codebook_template <- data.frame(variable = colnames(data_processed)) |>
    mutate(explanation = NA)
  # write to disk as an excel file
  write.xlsx(codebook_template, file = "../data/processed/data_processed_codebook.xlsx")
}

```

Note that there are other ways of automatically creating more elaborate codebooks from your datasets. These often contain information about min/max/mean/SD, distribution, etc. For example:

- Ruben Arslan's {codebook}
  - [R package with How-Tos](https://rubenarslan.github.io/codebook/)
  - [Tutorial](https://rubenarslan.github.io/codebook/articles/codebook_tutorial.html)
  - [Article](https://journals.sagepub.com/doi/full/10.1177/2515245919838783)
- Petersen & Ekstrøm's {dataReporter}
  - [Article](https://www.jstatsoft.org/article/view/v090i06)
  - [Blog](https://sandsynligvis.dk/2017/08/21/datamaid-your-personal-assistant-for-cleaning-up-the-data-cleaning-process/)
  - [R package](https://cran.r-project.org/web/packages/dataReporter/index.html)

# Session info

```{r}

sessionInfo()

```



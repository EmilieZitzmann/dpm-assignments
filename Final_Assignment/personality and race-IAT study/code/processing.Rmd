---
title: "Examining the relationship between the big-5 personality facets and implicit racial attitudes"
subtitle: "Data processing"
author: "Template: Ian Hussey; content: Emilie"
date: "`2023-12-28`"
output:
  html_document:
    code_folding: hide
    highlight: haddock
    theme: flatly
    toc: yes
    toc_float: yes
---

```{r, include=FALSE}
#By this we set the knitr options (warnings and messages generated through R will not be shown in the final document)

knitr::opts_chunk$set(message = FALSE,
                      warning = FALSE)


```

# Dependencies

```{r}

library(tidyverse)
library(janitor) 
library(stringr)
library(openxlsx)


```

# Get data

```{r}

# Demographics
data_raw_demographics <- read_csv("../data/raw/data_raw_demographics.csv") |>
  janitor::clean_names()

# Self report measure big five inventory 
data_raw_bfi <- read_csv("../data/raw/data_raw_bfi.csv") |>
  janitor::clean_names()

# Implicit association test
data_raw_iat <- read_csv("../data/raw/data_raw_iat.csv") |>
  janitor::clean_names()

```

# Demographics

Study participants had the option to provide their age and gender, although this was optional, meaning that missing data is not considered an exclusion criterion in this context. 


## Extraction of Age and Gender
Age and Gender should be extracted from the data frame. As these are both within "variable" we have to create two new variables by using pivot_wider. Beforehand we filter out people that were not assigned an individual_id as it makes no sense including data of unidentifiable subjects. Values other than the specified ones are set to "other/missing/error" in order to exclude them only at a later point, if needed. 

```{r}

dat_age_gender <- data_raw_demographics |>
  select(unique_id, variable, response) |>
  filter(!is.na(unique_id)) |> 
  pivot_wider(names_from = variable,
              values_from = response,
              values_fill = list(response = "other/missing/error")) |> #in case the specified has missing                                                                           entries
  rename(gender = sex) |>
  mutate(gender = case_when( gender %in% c("f", "m") ~ gender, #returns current value for gender if TRUE
                             is.na(gender) ~ "other/missing/error", #if gender equals NA
                             TRUE ~ "other/missing/error"), #if none of the set conditions is true 
         age = case_when(str_detect(age, "^[0-9]+$") ~ age, #setting the wanted value for age = number
                         is.na(age) ~ "other/missing/error",#if age equals NA
                         TRUE ~ "other/missing/error")) #if none of the other conditions is true
  


#Things from before I might still need 

dat_check_id <- data_raw_demographics |>
  select(unique_id, variable, response) |>
  mutate(missing_Id = ifelse (is.na(unique_id), "missing", "okay")) |>
  group_by(unique_id) |>
  pivot_wider(names_from = variable,
              values_from = response) |>
  rename(Gender = sex) 

dat_check_id |> 
  filter(unique_id == "missing") |> 
  kable() |> 
  kable_classic(full_width = FALSE)


#Relabel "sex" to Gender
dat_age_gender <- dat_age_gender 
row.names(dat_age_gender)[2] <- "Gender"

#Relabel "age" to Age
dat_age_gender <- dat_age_gender 
row.names(dat_age_gender)[1] <- "Age"


# Extract Gender and Age
Gender <- dat_age_gender["Gender", , drop = F] #if we put drop = F the result will remain a dataframe
Age <- dat_age_gender["Age", , drop = F]

# Print the result
view(Gender)
view(Age)


```


#BFI 

As part of the study, each respondent was asked to complete between two and three subscales of the Big 5 personality inventory.



## Reverse Score negatively worded items

Specific items were worded negatively. These items need to be reversed in order to be suitable for analysis. This applies to the items: 

•	the extroversion scale items 2, 5 and 7 
  (bfi_e2, bfi_e5, bfi_e7)
•	conscientiousness items 2, 4, 5 and 9
  (bfi_c2, bfi_c4, bfi_c5, bfi_c9)
•	neuroticism items 2, 5, and 7
  (bfi_n2, bfi_n5, bfi_n7)
•	agreeableness 1, 3, 6, and 8, and 
  (bfi_a1, bfi_a3, bfi_a6, bfi_a8)
•	openness items 7 and 9
  (bfi_o7, bfi_o9)

Each value can reach a maximum of 6 and a minimum of 1. In order to return the Items we must remember that the reverted scale is behaving inversely to the positive one so 1 = 6, 2 =5, 3=4, 4=3, 2= 5, 6=1. 
The easiest way to revert a Scale is  to add 1 to the maximum value in order to subtract the original value from it. This way we get the reversed score value. 

In order to modify the data we take mutate, with across we are able to apply this functions to multiple columns, all of specifices the columns of the vector we created . reprensents the column values and ~7 means that it substracts the column values from 7 

```{r}

vector_reversed_items <- c("bfi_e2","bfi_e5","bfi_e7","bfi_c2","bfi_c4","bfi_c5","bfi_c9","bfi_n2","bfi_n5", "bfi_n7","bfi_a1", "bfi_a3","bfi_a6","bfi_a8","bfi_o7","bfi_o9")


dat_reversed_items <- data_raw_bfi |>
  mutate(across(all_of(vector_reversed_items), ~7 - .))
 

```

###Sanity Check 
To check whether the reversals are likely to be correct a correlation matrix for each variable is created. If the correlation is negative or rather low it could indicate that the reversing was not carried out properly. In order to make sure that the correlation stayed the same the correlation matrix is calculated with the original dataset and compared with the reversed one. As the Big Five tend to be normally distributed the pearson correlation is used to calculate the matrix. The "use" within the correlation function is set to complete.obs, which means that variables who are missing data are not included. This is important considering that the participants only filled out two or three of the subscales which is producing some NA. 

```{r}

#Extroversion
Matrix_extroversion_reversed <- dat_reversed_items |>
  select(contains("bfi_e")) |>
  cor(method = "pearson", use = "complete.obs")

Matrix_extroversion_original <- data_raw_bfi |>
   select(contains("bfi_e")) |>
  cor(method = "pearson", use = "complete.obs")


#Conscientiousness 
Matrix_conscient_reversed <- dat_reversed_items |>
  select(contains("bfi_c")) |>
  cor(method = "pearson", use = "complete.obs")

Matrix_conscient_original <- data_raw_bfi |>
   select(contains("bfi_c")) |>
  cor(method = "pearson", use = "complete.obs")


#Neuroticism
Matrix_neuroticism_reversed <- dat_reversed_items |>
  select(contains("bfi_n")) |>
  cor(method = "pearson", use = "complete.obs")

Matrix_neuroticism_original <- data_raw_bfi |>
   select(contains("bfi_n")) |>
  cor(method = "pearson", use = "complete.obs")


#Agreeableness
Matrix_agreeable_reversed <- dat_reversed_items |>
  select(contains("bfi_a")) |>
  cor(method = "pearson", use = "complete.obs")

Matrix_agreeable_original <- data_raw_bfi |>
   select(contains("bfi_a")) |>
  cor(method = "pearson", use = "complete.obs")


#Openness
Matrix_openness_reversed <- dat_reversed_items |>
  select(contains("bfi_o")) |>
  cor(method = "pearson", use = "complete.obs")

Matrix_openness_original <- data_raw_bfi |>
   select(contains("bfi_o")) |>
  cor(method = "pearson", use = "complete.obs")



```


Check that the item level data does not violate the logical minimum and maximum scores (1 to 6). Create an exclusion variable and set participants with impossible data to “exclude”. The columns are selected with c_across and we only select the ones that contain information with bfi


```{r}

#Defining the vector for maximum and minimum 

logical_min <- 1 
logical_max <- 6

#creating the dataset 
data_logical_number <- dat_reversed_items |>
  rowwise() |>
  mutate(logical_number = ifelse(any(!is.na(c_across(contains("bfi"))) & #selected values are not NA
                                     (c_across(contains("bfi")) < logical_min | 
                                      c_across(contains("bfi")) > logical_max)),
                                 "exclude",
                                 "include"))
```


Check that all participants have complete data on the BFI scales they completed. Create an exclusion variable and set participants with incomplete data to “exclude”.

In order to check this we set the ifelse to all, as we want just participants that have completed all information in at least one questionnaire. We do this for every questionnaire and then we can check whether it looks about right by arranging it with arrange(). We can see that it worked as for example 232178 has a missing value in extraversion although it might have completed the questionnaire yet it is excluded. We use the left_join as we know that there is no duplicated ID (hier müsste ich dann aber noch integrieren, was oben gemacht wurde in der ersten Aufgabe mit filter), we know that all of the same information exists in all of the datasets and unique id is the same in all of them --> will not mess up 


```{r}

#Extroversion
data_extroversion_exclusion <- dat_reversed_items |> 
  rowwise() |> 
  mutate(completed_q_e = ifelse(all(!is.na(c_across(contains("bfi_e")))), "include", "exclude")) |>
  arrange(completed_q_e) 


#After we have checked that it seems pretty right we filter out the existing ones: 

#Extroversion
 data_extroversion_exclusion <- dat_reversed_items |> 
   rowwise() |> 
   mutate(completed_q_e = ifelse(all(!is.na(c_across(contains("bfi_e")))), "include", "exclude")) |>
   filter(completed_q_e != "exclude")
 
#Conscientiousness
data_conscient_exclusion <- dat_reversed_items |> 
  rowwise() |> 
  mutate(completed_q_c = ifelse(all(!is.na(c_across(contains("bfi_c")))), "include", "exclude")) |> 
  filter(completed_q_c != "exclude")
 

#Neuroticism
data_neuroticism_exclusion <- dat_reversed_items |> 
  rowwise() |> 
  mutate(completed_q_n = ifelse(all(!is.na(c_across(contains("bfi_n")))), "include", "exclude")) |>
  filter(completed_q_n != "exclude")

#Agreeableness
data_agreeable_exclusion <- dat_reversed_items |> 
  rowwise() |> 
  mutate(completed_q_a = ifelse(all(!is.na(c_across(contains("bfi_a")))), "include", "exclude")) |>
  filter(completed_q_a != "exclude")

#Openness
data_openness_exclusion <- dat_reversed_items |> 
  rowwise() |> 
  mutate(completed_q_o = ifelse(all(!is.na(c_across(contains("bfi_o")))), "include", "exclude")) |>
  filter(completed_q_o != "exclude")




#combining all of the information above within one dataframe 

data_combined_exclusion <- dat_reversed_items |>
  select(unique_id) |>
  left_join(data_extroversion_exclusion |>
            select(unique_id, completed_q_e), by = "unique_id") |>
  left_join(data_conscient_exclusion |>
            select(unique_id, completed_q_c), by = "unique_id") |>
  left_join(data_neuroticism_exclusion |>
            select(unique_id, completed_q_n), by = "unique_id") |>
  left_join(data_agreeable_exclusion |>
            select(unique_id, completed_q_a), by = "unique_id") |>
  left_join(data_openness_exclusion |>
            select(unique_id, completed_q_o), by = "unique_id")


#Making a final dataframe

data_final_bfi <- dat_reversed_items |> 
  left_join(data_combined_exclusion, by = "unique_id")

#As it is not really a good overview who should be included or not we can mutate a final variable where we see if a person should be included or not. We overwrite it as we do need the other variable 

data_final_bfi <- data_final_bfi |>
  rowwise() |>
  mutate(overall_inclusion = ifelse(any(c(completed_q_e, 
                                          completed_q_c, completed_q_n, 
                                          completed_q_a, completed_q_o) =="include"),
                                    "include",
                                    "exclude"))

```


##Mean score BFI

Mean-score the subscales of the BFI scale. Each participant only got either 2 or 3 subscales.
Check that the mean scores do not violate the min and max possible score (i.e., first determine this min and max score), and revise your scoring code if it does.


We take dat reversed Items but probably after the interpretation we have to be more careful with it 

```{r}

data_mean_bfi <- dat_reversed_items |> 
  rowwise() |>
  mutate(mean_extroversion = mean(c_across(contains("bfi_e")), na.rm =T),
         mean_conscient = mean(c_across(contains("bfi_c")), na.rm = T),
         mean_neuroticism = mean(c_across(contains("bfi_n")), na.rm = T),
         mean_agreeable = mean(c_across(contains("bfi_a")), na.rm =T),
         mean_openness = mean(c_across(contains("bfi_o")), na.rm =T))


#Check for violation of the scores, do not take the same vector name as above because if there is some change done in either of them the calculation will be confused.

min_possible_score <- 1  
max_possible_score <- 6  

#Still issues with this 

data_mean_violation_bfi <- data_mean_bfi |>
  rowwise() |>
  mutate(score_violation = ifelse(any(c_across(contains("bfi")) 
                                      < min_possible_score | c_across(contains("bfi")) 
                                      >max_possible_score, na.rm = T),
                                  "yes", 
                                  "no")) |>
  ungroup() |>
  select(unique_id, mean_extroversion, mean_conscient, mean_neuroticism, mean_agreeable, mean_openness,
         score_violation)
 





```



```{r}

data_amp_performance_criteria <- data_amp_raw |> 
  filter(blockcode != "practice", 
         trialcode != "instructions") |> 
  mutate(latency_prob = if_else(latency < 100, TRUE, FALSE)) |> 
  group_by(subject) |> 
  summarize(proportion_fast_trials_amp = mean(latency_prob)) |>
  mutate(exclude_amp_performance = ifelse(proportion_fast_trials_amp > 0.10, "exclude", "include"))

# determine modal number of trials
data_amp_completeness <- data_amp_raw |>
  filter(blockcode != "practice",
         trialcode != "instructions") |>
  group_by(subject) |>
  count() |>
  ungroup() |>
  mutate(exclude_amp_completeness = ifelse(n == 72, "include", "exclude")) |>
  select(-n)

# data_amp_completeness |>
#   count(n)

```

- One participant with 8 trials appears to be a partial completion (check raw data?)
- One participant with 144 trials appears to be a repeat participant. I've chosen to exclude them entirely, but you could also have a more elaborate strategy where you retain only their first completion.

# Self-reports

```{r}

# trial level data
data_selfreport_trial_level <- data_selfreport_raw |>
  select(subject, trialcode, response) |>
  filter(trialcode %in% c("like", "prefer", "positive")) |>
  rename(item = trialcode) |>
  filter(response != "Ctrl+'B'") |>
  mutate(response = as.numeric(response))

# mean scored
data_selfreport_mean_score <- data_selfreport_trial_level |>
  group_by(subject) |>
  summarize(mean_evaluation = mean(response, na.rm = TRUE))

# combined
data_selfreport_scored <- 
  full_join(data_selfreport_trial_level |>
              pivot_wider(names_from = "item",
                          values_from = "response"),
            data_selfreport_mean_score,
            by = "subject")

```

# Affect Misattribution Procedure

TODO extract evaluations on the AMP test blocks and convert to an overall bias score

```{r}

data_amp_score_congruence <- data_amp_raw |> 
  select(subject, evaluative_response = correct, trialcode, blockcode) |> 
  filter(blockcode != "practice", 
         trialcode != "instructions") |> 
  mutate(trialcode = case_when(trialcode == "prime_positive" ~ 1, 
                               trialcode == "prime_negative" ~ 0,
                               TRUE ~ NA),
         prime_congruence = ifelse(trialcode == evaluative_response, 1, 0)) 

# sanity check 1: if you consider all the combiantions of factor levels of trialcode, evaluative_response, and prime congruence, there should be only 4:
data_amp_score_congruence |>
  count(trialcode, evaluative_response, prime_congruence)

data_amp_score_congruence |>
  count(trialcode, evaluative_response, prime_congruence) |>
  nrow() == 4

# calculate AMP score 
data_amp_score <- data_amp_score_congruence |> 
  group_by(subject) |> 
  summarize(AMP_score = mean(prime_congruence, na.rm = TRUE)) |> 
  select(subject, AMP_score)

# sanity check 2: check if AMP_score is numeric 
is.numeric(data_amp_score$AMP_score)

# sanity check 3: check if AMP_score is bounded [0,1]
data_amp_score |> 
  mutate(bounded_correctly = between(AMP_score, left = 0, right = 1)) |>
  filter(bounded_correctly != TRUE) |>
  nrow() == 0

```

# Combine

```{r}

# combine all dfs created in the previous chunks
data_processed_temp <- dat_age_gender |>
  full_join(data_selfreport_scored, by = "subject") |> 
  full_join(data_amp_score, by = "subject") |> 
  full_join(data_amp_performance_criteria, by = "subject") |>
  full_join(data_amp_completeness, by = "subject")

# flag all subjects with more than one row in the wide-format data. these should be excluded in the analysis.
# a more elaborate approach would be to track down the individual dupicate cases and determine which of the mulitiple cases should be retained. 
data_processed_duplicates <- data_processed_temp |>
  count(subject) |>
  mutate(exclude_duplicate_data = if_else(n > 1, "exclude", "include")) |>
  select(-n)

# join in the duplicates df
data_processed_before_exclusions <- data_processed_temp |>
  full_join(data_processed_duplicates, by = "subject")

```

# Define master exclusions

```{r}

# create a master exclude_participant variable
data_processed <- data_processed_before_exclusions |>
  mutate(exclude_participant = case_when(tolower(age) == "test" ~ "exclude",
                                         tolower(gender) == "test" ~ "exclude",
                                         is.na(mean_evaluation) ~ "exclude",
                                         # in this case we will exclude participants with missing demographics data or outcomes measures data. 
                                         # Note that "list-wise exclusions" like this aren't always justified, as missingness often isn't at random. 
                                         # How to treat missing data is a  whole area of work in itself, which we wont cover here.
                                         is.na(age) ~ "exclude", 
                                         is.na(gender) ~ "exclude",
                                         exclude_amp_performance == "exclude" ~ "exclude",
                                         exclude_duplicate_data == "exclude" ~ "exclude",
                                         exclude_amp_completeness == "exclude" ~ "exclude", 
                                         TRUE ~ "include"))

```

# Write to disk

```{r}

# in case this dir doesn't exist, create it
dir.create("../data/processed/")

# save data to disk in that dir
write_csv(data_processed, "../data/processed/data_processed.csv")

```

# Create codebook template for the processed data

If it has not already been created, this code write the codebook template to disk. 

\TODO The template should then be filled in manually with descriptions of each variable so that someone else could understand what these variables represent. 

Be sure to ALWAYS do it, since people forget the labels, the maximum and minimum values etc. We should also specify what they should be (numeric etc.)


I filled out some parts of the codebook but I am not sure whether it is visible on Github:)

```{r}

if(!file.exists("../data/processed/data_processed_codebook.xlsx")){
  # convert the column names to a df
  codebook_template <- data.frame(variable = colnames(data_processed)) |>
    mutate(explanation = NA)
  # write to disk as an excel file
  write.xlsx(codebook_template, file = "../data/processed/data_processed_codebook.xlsx")
}

```

Note that there are other ways of automatically creating more elaborate codebooks from your datasets. These often contain information about min/max/mean/SD, distribution, etc. For example:

- Ruben Arslan's {codebook}
  - [R package with How-Tos](https://rubenarslan.github.io/codebook/)
  - [Tutorial](https://rubenarslan.github.io/codebook/articles/codebook_tutorial.html)
  - [Article](https://journals.sagepub.com/doi/full/10.1177/2515245919838783)
- Petersen & Ekstrøm's {dataReporter}
  - [Article](https://www.jstatsoft.org/article/view/v090i06)
  - [Blog](https://sandsynligvis.dk/2017/08/21/datamaid-your-personal-assistant-for-cleaning-up-the-data-cleaning-process/)
  - [R package](https://cran.r-project.org/web/packages/dataReporter/index.html)

# Session info

```{r}

sessionInfo()

```



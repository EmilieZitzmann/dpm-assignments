---
title: "Plot assignment"
author: "Template: Ian Hussey; content: Emilie"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  html_document:
    code_folding: hide
    highlight: haddock
    theme: flatly
    toc: yes
    toc_float: yes
---
```{r, include=FALSE}

knitr::opts_chunk$set(message = FALSE,
                      warning = FALSE)

```

Tell him what we want to do with the good plot and what it shows, in the bad plot we don't turn the alpha value low, we use bad colors, that don't help the lines stand outt, clearly not distinct colors, communicate what we did to make the bad plot confusing and the good plot good --> we should get what a good plot is all about and add layers --> produce a reproduceable plot, the data can be made up if we choose, we can use rnorm as in the file, we can put data in an excel frame, real data from open science, no restrictions on what the data is --> it does not matter. The plot should be reproduceable, it should be evident that we got what a good plot is about and what not, the story of the data should be told correctly --> it does not have to make sense.
The plot should not be too basic, barplot no, but also it should not be a plot that nobody uses --> Raincloud plots are good and really informative, people actually use them --> Balance between looking nice and being useful and filled with information --> Plots in publications are a bit simpler than the ones in infographics, we can also imitate one that was in an infographic or in a blog, data is beautiful is NOT a good source (be careful with it, the choice sometimes is not too great).

Return the data, the code, either png or pdf file of the plot --> final assignment, try citing source if not too much (the book from Lisa for example) 1x each, the plots don't have to be the same but they should have some correspondance (both of the plot should try to explain the same thing --> Raincloud does it well and pie chart not for example)




# Dependencies

```{r}

library(tidyverse)

```


# Get Data 

The data set utilized for the plot was downloaded from osf.io. As such, it is the final data set of the study "Is video games' effect on attitudes universal? Results from an empirical study comparing video games impact on the attitude change of players with different backgrounds" by Kolek et al. (2023). The authors investigate whether a video game has an impact on explicit and implicit attitudes. Based on the available data set, it was possible to detect a shift on the explicit attitudes.  

```{r}

data_video_games_raw <- read_csv("../data/raw/cs3_2_final_data_without_age.csv") |>  
janitor::clean_names()

```

# Sources 
 - Link to the article: https://onlinelibrary.wiley.com/doi/10.1111/jcal.12911
 - Link to the dataset: https://osf.io/f23cb
 
# Modifications to dataset

Some modifications have been applied to the dataset in order to visualize certain aspects within the plot. It is important to note that these modifications may not correspond to those intended by the authors and therefore may not represent the exact variables.

```{r}

data_video_games_processed <- data_video_games_raw |>
  rename(Pretest_PANAS_Negative = pre_pana_sn,
         Pretest_PANAS_Positive = pre_pana_sp,
         Posttest_PANAS_Negative = post_pana_sn,
         Posttest_PANAS_Positive = post_pana_sp) |>
  mutate(education = case_when(
    education == "S" ~ "Secondary Education",
    education == "Z" ~ "University",
    TRUE ~ education ),
    group = case_when(
    group == "C" ~ "Control Group",
    group == "E" ~ "Experimental Group",
    TRUE ~ group))

```

## Write the modifications to Disk 

```{r}

# in case this dir doesn't exist it is created
dir.create("../data/processed/")

# save data to disk in that dir
write_csv(data_video_games_processed, "../data/processed/data_video_games_processed.csv")

```

# Analysis of the Dataset

The PANAS (Positive and Negative Affect Schedule) is a questionnaire that is widely used to measure mood or emotions. It is based on a 5-point Likert scale measuring the positive or negative affect on a total score ranging between 10 and 50. The higher scores on the positive scale represent a more positive affect and the higher sores on the negative scale represent a more negative affect. Ein Mittelwertsvergleich zwischen den positiven und negativen Skalen jeweils vor und nach der Exposittion wird graphisch dargestellt, um zu erkennen, ob die Exposition einen Einfluss auf die affektiven Zust√§nde innerhalb der Versuchspersonen nimmt. Wichtig ist, dass dabei die Experimental- und Kontrollgruppe getrennt werden, um so auch zu sehen, ob und inwiefern sich die unterschiedlichen Expositionen auswirken. 

A mean comparison between the positive and negative scales before and after the exposure is shown graphically in order to recognize whether the exposure has an influence on the affective states within the test subjects. It is important that the experimental and control groups are separated in order to see whether and to what extent the different exposures have an effect


# Instructions

The goal of this exercise is to produce both good and bad examples of plots *and to be explicit about what makes them good or bad*. 

The data can be real or fabricated. The plots can convey realistic or silly messages - but they must convey them clearly. You can get real data from many sources. A good one is the open science framekwork (osf.io). You can also simply make up data, either by hand or using simulation functions (e.g., `rnorm`) or the many simulation packages. If simulating data, ensure that you (a) use set.seed() to make it reproudbile, and (b) save a copy of the final data that you're using to disk and then reload it in the script so that the plot is reproducible.

The goal is neither to reproduce the types of plots that you most often see in journals (bar plots, etc.) nor to use a very fancy looking plot just for the sake of it - if it is very unlikely that you'd ever be able to use the plot to convey a research finding in an article, blog, poster, tweet, infographic or otherwise, it's probably not a good choice either.

The plots must be reproducible. Provide the data as well as the code to reporduce them. The plots should also be saved as individual images (pdf or png).

Under each plot, here in the RMarkdown, briefly explain what types of analysis the plot is suitable for, what elements of the results the plot attempts to clearly convey. For the bad plot, do the opposite: emphasise what features of the results the plot obscures or makes unclear. In doing so, communicate to me that you understand what makes a good plot to convey the results of quantiative analyses to viewers.

Consider making use of the many extensions to ggplot2, e.g.: Good sources ( see if we can integrate them)

- https://r-graph-gallery.com
- https://krzjoa.github.io/awesome-r-dataviz/#/
- ggdist https://mjskay.github.io/ggdist/
- ggrepel
- ggpubr
- see
- ggsignif
- and others: https://exts.ggplot2.tidyverse.org/gallery/

# Plot 

```{r}

## Negative Data
Negative_Data <- data_video_games_processed |>
  select(Pretest_PANAS_Negative, Posttest_PANAS_Negative)

Negative_data_long <- Negative_Data |>
  pivot_longer(cols = c(Pretest_PANAS_Negative, Posttest_PANAS_Negative),
               names_to = "Test_Type",
               values_to = "Score")

## Positive Data
Positive_Data <- data_video_games_processed |>
  select(Pretest_PANAS_Positive, Posttest_PANAS_Positive)

Positive_data_long <- Positive_Data |>
  pivot_longer(cols = c(Pretest_PANAS_Positive, Posttest_PANAS_Positive),
               names_to = "Test_Type",
               values_to = "Score")

# Set the order for the plots according to Test_Type

## Negative
Negative_data_long$Test_Type <- factor(Negative_data_long$Test_Type, levels = c("Pretest_PANAS_Negative", 
                                                                                "Posttest_PANAS_Negative"))

## Positive 
Positive_data_long$Test_Type <- factor(Positive_data_long$Test_Type, levels = c("Pretest_PANAS_Positive", 
                                                                                "Posttest_PANAS_Positive"))

# Calculate the mean values to include them within the plot to make the mean more visible 

## Negative 
mean_values_negative <- Negative_data_long |>
  group_by(Test_Type) |>
  summarise(mean_score = mean(Score, na.rm = TRUE))

## Positive 
mean_values_positive <- Positive_data_long |>
  group_by(Test_Type) |>
  summarise(mean_score = mean(Score, na.rm = TRUE))

# Create the plot
Plot_Negative <- ggplot(Negative_data_long,
                        aes(x = Test_Type, 
                            y = Score, 
                            fill = Test_Type, 
                            color = Test_Type)) +
  geom_violin(trim = FALSE, 
              alpha = 0.5) +
  geom_boxplot(width = 0.2, 
               alpha = 0.6, 
               color = "black", 
               outlier.shape = 16, 
               outlier.color = "red") +
  geom_text(data = mean_values_negative, 
            aes(x = Test_Type, 
                y = max(Negative_data_long$Score) + 5, 
                label = sprintf("%.2f",
                                mean_score)),
            position = position_dodge(width = 0.75), 
            vjust = -0.5, 
            size = 3, 
            show.legend = FALSE, 
            inherit.aes = FALSE) +
  labs(title = "Distribution of Negative Scores Before and After Exposure",
       subtitle = "Comparing Pre- and Posttest", 
       x = NULL, #Remove the x-Axis Label as it provides no additional information 
       y = "Score Range") +
  coord_cartesian(ylim = c(0, 50)) +  # Set y-axis limit up to 50, since PANAS max is 50 
  scale_fill_manual(values = c("#4C72B0", "#DD8452"), name = "Test Type") +
  scale_color_manual(values = c("#4C72B0", "#DD8452"), name = "Test Type") +
  theme_minimal()+
  guides(fill = FALSE, color = FALSE) + #Remove legend
  scale_x_discrete(labels = c("Pretest", "Posttest")) #Modify x-Axis labels 

# Display the plot
print(Plot_Negative)


# Create the plot for Positive Data
Plot_Positive <- ggplot(Positive_data_long,
                        aes(x = Test_Type, 
                            y = Score, 
                            fill = Test_Type, 
                            color = Test_Type)) +
  geom_violin(trim = FALSE, 
              alpha = 0.5) +
  geom_boxplot(width = 0.2, 
               alpha = 0.6, 
               color = "black", 
               outlier.shape = 16, 
               outlier.color = "red") +
  geom_text(data = mean_values_positive, 
            aes(x = Test_Type, 
                y = max(Positive_data_long$Score) + 5, 
                label = sprintf("%.2f",
                                mean_score)),
            position = position_dodge(width = 0.75), 
            vjust = -0.5, 
            size = 3, 
            show.legend = FALSE, 
            inherit.aes = FALSE) +
  labs(title = "Distribution of Positive Scores Before and After Exposure",
       subtitle = "Comparing Pre- and Posttest", 
       x = NULL, 
       y = "Score Range") +
  coord_cartesian(ylim = c(0, 50)) + 
  scale_fill_manual(values = c("#4C72B0", "#DD8452"), name = "Test Type") +
  scale_color_manual(values = c("#4C72B0", "#DD8452"), name = "Test Type") +
  theme_minimal() +
  guides(fill = FALSE, color = FALSE) + 
  scale_x_discrete(labels = c("Pretest", "Posttest")) 


print(Plot_Positive)


Combined_Plot <- ggplot(Combined_data_long,
                        aes(x = Test_Type, y = Score, fill = Test_Group, color = Test_Group)) +
  geom_violin(trim = FALSE, alpha = 0.5) +
  geom_boxplot(width = 0.2, alpha = 0.6, color = "black", outlier.shape = 16, outlier.color = "red") +
  geom_text(data = mean_values_combined,
            aes(x = Test_Type, y = max(Combined_data_long$Score) + 5, label = sprintf("%.2f", mean_score)),
            position = position_dodge(width = 0.75),
            vjust = -0.5,
            size = 6,
            show.legend = FALSE,
            inherit.aes = FALSE,
            color = "darkred",
            fontface = "bold") +
  labs(title = "Distribution of Scores Before and After Exposure",
       subtitle = "Comparing Pre- and Posttest",
       x = NULL,
       y = "Score Range") +
  coord_cartesian(ylim = c(0, 60)) +  #Remove the 60 later only left it in because of the mean that is not shown otherwhise
  scale_fill_manual(values = c("#4C72B0", "#DD8452"), name = "Test Group") +
  scale_color_manual(values = c("#4C72B0", "#DD8452"), name = "Test Group") +
  common_theme +
  theme(plot.margin = margin(1, 1, 1, 1, "cm"),  #for prettier borders (Abstand des Plots)
        strip.text = element_text(size = 10)) +
  scale_x_discrete(labels = c("Pretest_Negative", "Posttest_Negative", "Pretest_Positive", "Posttest_Positive"))

print(Combined_Plot)

```
###Trying to find a way putting the mean values as a legend
TODO: 
- Find a way to include the mean values better (preferably legend)
- Modify the distance from Score Range it is really close to y axis 
- Probably check whether this is APA worthy ?? 
- Make several chunks one for Negative, one for Positive and one for the combined 

```{r}



```


# Bad plot

```{r}



```

# Write to disk

Write to disk as a .pdf or .png.

Name them "plot_good_[yourname]" and "plot_bad_[yourname]".

```{r}



```

# Session info

```{r}

sessionInfo()

```



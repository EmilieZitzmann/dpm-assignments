---
title: "Evaluations of positive and negative stimuli using the Affective Misattribution Procedure (AMP) and self-reports"
subtitle: "Data processing"
author: "Template: Ian Hussey; content: Emilie"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  html_document:
    code_folding: hide
    highlight: haddock
    theme: flatly
    toc: yes
    toc_float: yes
---

```{r, include=FALSE}

knitr::opts_chunk$set(message = FALSE,
                      warning = FALSE)

```

# Dependencies

```{r}

library(tidyverse)
library(janitor) # for clean_names()
library(stringr)
library(knitr)

```

# Get data

```{r}

# demographics
data_demographics_raw <- read_csv("../data/raw/data_demographics_raw.csv") %>% 
  janitor::clean_names()

# data_demographics_raw_messy <- read_csv("../data/raw/data_demographics_raw_messy.csv", skip = 2) |>
#   janitor::clean_names()

# self report measure
data_selfreport_raw <- read_csv("../data/raw/data_selfreport_raw.csv") %>% 
  janitor::clean_names()

# affect attribution procedure
data_amp_raw <- read_csv("../data/raw/data_amp_raw.csv") %>% 
  janitor::clean_names()

```

# Demographics

```{r}

dat_age_gender <- data_demographics_raw %>% 
  select(subject, date, time, trialcode, response) %>% 
  pivot_wider(names_from = trialcode,
              values_from = response) %>% 
  mutate(gender = tolower(gender),
         gender = stringr::str_remove_all(gender, regex("\\W+")), # regex is both very useful and awful to write
         gender = case_when(gender == "female" ~ gender,
                            gender == "male" ~ gender,
                            gender == "nonbinary" ~ gender,
                            gender == "woman" ~ "female",
                            gender == "man" ~ "male",
                            TRUE ~ "other/missing/error"),
         age = case_when(str_detect(age, "^[0-9]+$") ~ age, # if the value is only numbers, keep it. 
                         TRUE ~ "other/missing/error")) 

```

# Exclusions / data quality

## AMP

```{r}

data_amp_performance_criteria <- data_amp_raw %>% 
  filter(blockcode != "practice", 
         trialcode != "instructions") %>% 
  mutate(latency_prob = if_else(latency < 100, TRUE, FALSE)) %>%  
  group_by(subject) %>% 
  summarize(proportion_fast_trials_amp = mean(latency_prob)) %>% 
  mutate(exclude_amp_performance = ifelse(proportion_fast_trials_amp > 0.10, "exclude", "include"))

# determine modal number of trials
data_amp_completeness <- data_amp_raw %>% 
  filter(blockcode != "practice",
         trialcode != "instructions") %>% 
  group_by(subject) %>% 
  count() %>% 
  ungroup() %>% 
  mutate(exclude_amp_completeness = ifelse(n == 72, "include", "exclude")) %>% 
  select(-n)

# data_amp_completeness |>
#   count(n)

```

- One participant with 8 trials appears to be a partial completion (check raw data?)
- One participant with 144 trials appears to be a repeat participant. I've chosen to exclude them entirely, but you could also have a more elaborate strategy where you retain only their first completion.

# Self-reports

```{r}

# trial level data
data_selfreport_trial_level <- data_selfreport_raw %>% 
  select(subject, trialcode, response) %>% 
  filter(trialcode %in% c("like", "prefer", "positive")) %>% 
  rename(item = trialcode) %>% 
  filter(response != "Ctrl+'B'") %>% 
  mutate(response = as.numeric(response))

# mean scored
data_selfreport_mean_score <- data_selfreport_trial_level %>% 
  group_by(subject) %>% 
  summarize(mean_evaluation = mean(response, na.rm = TRUE))

# combined
data_selfreport_scored <- 
  full_join(data_selfreport_trial_level %>% 
              pivot_wider(names_from = "item",
                          values_from = "response"),
            data_selfreport_mean_score,
            by = "subject")

```

# Affect Misattribution Procedure

TODO extract evaluations on the AMP test blocks and convert to an overall bias score

```{r}

#The AMP was scored in the usual manner. Each participant’s score represented the proportion of prime-congruent ratings (i.e., positive primes that were rated positively, ie “1”; and negative primes that were rated negatively, ie “0), using only trials from the test blocks.
data_correct_trials <- data_amp_raw %>% 
  filter(blockcode != "practice",
         trialcode != "instructions") %>% 
  select(subject, trialcode, correct) %>% 
  mutate(prime_congruency = case_when((trialcode == "prime_positive" & 
                                         correct == 1 ) |
                                      (trialcode == "prime_negative" &
                                         correct == 0)~ "congruent", 
                                      TRUE ~"incongruent"))


#Create the amp_score variable: 

data_prob_correct <- data_correct_trials %>% 
                         group_by(subject) %>% 
                         summarize(amp_score = mean(prime_congruency == "congruent"))

                        
########Sanity Checks 

# 1.visual inspection

#we check whether the values we calculated are correct by picking a random subject out of the dataset and calculate the amp_score ourselves. We picked out individual 504546409 --> in the data correct trials we are able to see that the subject has 3 congruent trials out of 8

3/8

#--> 3/8 = 0.375 


#Now we calculate the whole thing with our code conducted before (the summarize part is the same as for our code above)
person_check <- data_correct_trials %>% 
  filter(subject == "504546409") %>% 
  summarize(amp_score = mean(prime_congruency == "congruent"))
#The value equals the same as the manual calculation --> we calculated the correct thing 


# 2. Sanity Check: 
#Do the proportions of congruent and incongruent trials sum up to one? 

#First we check the overall percentage and if the congruent and incongruent trials sum up to 1 --> this is the case (Note that you need janitor:: for tably function)
data_san_check_2 <- data_correct_trials %>% 
    select("prime_congruency") %>%
    na.omit(T) %>% 
    tabyl(prime_congruency) %>% 
    adorn_pct_formatting(digits = 2)

#now we take a closer look at the dataset, in order to do so we first conduct a new df with the proportion of incorrect trials 

data_prob_incorrect <- data_correct_trials %>% 
  group_by(subject) %>%
  summarize(amp_score = mean(prime_congruency == "incongruent"))

sanity_check_2 <- data_prob_correct %>% 
   full_join(data_prob_incorrect,by="subject") %>% 
   mutate(check2 = amp_score.x + amp_score.y) %>% 
  mutate(not_true = ifelse (check2 != 1, "exclude", "include"))

#We conducted a variable that flags all the combined proportion sums to "exclude" who do not equal 1. With this dataset (since it has only 100 participants) we can see by comparing the 2 datasets, that this is never the case. If the dataset is bigger we can use count or kable in order to check, or we can directly conduct a table using tabyl again:


data_test_san_2 <- sanity_check_2%>% 
    select("not_true") %>%
    na.omit(T) %>% 
    tabyl(not_true) %>% 
    adorn_pct_formatting(digits = 2)

#Thereby we see that all of the participants should be included since their incongruency and congruency sum equals 1 


#sanity check 3: 
#Logical Inspection: Is our code of prime congruency correct? Do all of our variables match each other (prime positive is correct and congruent?). 

# in order to check if all conditions match each other we created another variable. If something would be incongruent here we would have made a mistake before so it is really important, that we have no errors within all of these variables. 

sanity_check_3 <- data_correct_trials %>% 
  mutate(check3 = case_when((trialcode == "prime_positive" & 
                               correct == 1 &
                               prime_congruency == "congruent") |
                              (trialcode == "prime_negative" &
                                 correct == 0 &
                                 prime_congruency == "congruent")|
                              (trialcode == "prime_positive" &
                                 correct == 0 &
                                 prime_congruency == "incongruent") |
                              (trialcode == "prime_negative" &
                                 correct == 1 &
                                 prime_congruency == "incongruent")~ "yes",
                            TRUE ~"no"))


#Table in order to see if we have no
data_test_san_3 <- sanity_check_3%>% 
    select("check3") %>%
    na.omit(T) %>% 
    tabyl(check3) %>% 
    adorn_pct_formatting(digits = 2)

# we can see that all variables match each other and we have a total of 100% "yes"



```

# Combine

```{r}

# combine all dfs created in the previous chunks
data_processed_temp <- dat_age_gender %>% 
  full_join(data_selfreport_scored, by = "subject") %>%  
  full_join(data_amp_performance_criteria, by = "subject") %>% 
  full_join(data_amp_completeness, by = "subject")

# flag all subjects with more than one row in the wide-format data. these should be excluded in the analysis.
# a more elaborate approach would be to track down the individual dupicate cases and determine which of the mulitiple cases should be retained. 
data_processed_duplicates <- data_processed_temp %>% 
  count(subject) %>% 
  mutate(exclude_duplicate_data = if_else(n > 1, "exclude", "include")) %>% 
  select(-n)

# join in the duplicates df
data_processed_before_exclusions <- data_processed_temp %>% 
  full_join(data_processed_duplicates, by = "subject")

```

# Define master exclusions

```{r}

# create a master exclude_participant variable
data_processed <- data_processed_before_exclusions %>% 
  mutate(exclude_participant = case_when(tolower(age) == "test" ~ "exclude",
                                         tolower(gender) == "test" ~ "exclude",
                                         is.na(mean_evaluation) ~ "exclude",
                                         # in this case we will exclude participants with missing demographics data or outcomes measures data. 
                                         # Note that "list-wise exclusions" like this aren't always justified, as missingness often isn't at random. 
                                         # How to treat missing data is a  whole area of work in itself, which we wont cover here.
                                         is.na(age) ~ "exclude", 
                                         is.na(gender) ~ "exclude",
                                         exclude_amp_performance == "exclude" ~ "exclude",
                                         exclude_duplicate_data == "exclude" ~ "exclude",
                                         exclude_amp_completeness == "exclude" ~ "exclude", 
                                         TRUE ~ "include"))

```

# Write to disk

```{r}

# in case this dir doesn't exist, create it
dir.create("../data/processed/")

# save data to disk in that dir
write_csv(data_processed, "../data/processed/data_processed.csv")

```

# Session info

```{r}

sessionInfo()

```


